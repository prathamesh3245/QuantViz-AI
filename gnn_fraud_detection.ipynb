{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86809bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphSAGE\n",
    "from torch_geometric.datasets import EllipticBitcoinDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EllipticBitcoinDataset(root='/data')\n",
    "data = dataset[0]\n",
    "# transactions = pd.read_csv(\"elliptic_txs_classes.csv\")\n",
    "# edges = pd.read_csv(\"elliptic_txs_edgelist.csv\")\n",
    "# print(transactions)\n",
    "# print(edges)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d5b9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])\n"
     ]
    }
   ],
   "source": [
    "elliptic = EllipticBitcoinDataset(root='/data')._data\n",
    "print(elliptic)\n",
    "# fraud_dict = dict(zip(transactions['txId'], transactions['class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7491593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges move out of the following nodes:\n",
      " tensor([     0,      2,      4,  ..., 201921, 201480, 201954])\n",
      "\n",
      "edges move into the following nodes:\n",
      " tensor([     1,      3,      5,  ..., 202042, 201368, 201756])\n"
     ]
    }
   ],
   "source": [
    "out_nodes = elliptic.edge_index[0]\n",
    "print('edges move out of the following nodes:\\n', out_nodes)\n",
    "\n",
    "in_nodes = elliptic.edge_index[1]\n",
    "print('\\nedges move into the following nodes:\\n', in_nodes)\n",
    "# G = nx.from_pandas_edgelist(edges, 'txId1', 'txId2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_matrix = torch_geometric.utils.to_dense_adj(elliptic.edge_index)\n",
    "# print(dense_matrix)\n",
    "\n",
    "## node_colors = []\n",
    "## for node in G.nodes():\n",
    "##     if node in fraud_dict:\n",
    "##         if fraud_dict[node] == 2:\n",
    "##             node_colors.append('red')\n",
    "##         elif fraud_dict[node] == 1:\n",
    "##             node_colors.append('blue')\n",
    "##     else:\n",
    "##         node_colors.append('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05d8d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Truth values: \", elliptic.y)\n",
    "# elliptic_to_x = torch_geometric.utils.to_networkx(elliptic, to_undirected=True)\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# nx.draw(elliptic_to_x, with_labels=True, node_color=elliptic.y)\n",
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "# from torch_geometric.data import Data\n",
    "# import numpy as np\n",
    "\n",
    "# # Load data SMARTLY\n",
    "# features = pd.read_csv(\"elliptic_txs_features.csv\", header=None)\n",
    "# classes = pd.read_csv(\"elliptic_txs_classes.csv\")\n",
    "# edgelist = pd.read_csv(\"elliptic_txs_edgelist.csv\")\n",
    "\n",
    "# # Preprocess (keep only labeled nodes)\n",
    "# labeled_ids = classes[classes['class'] != 'unknown']['txId'].values\n",
    "# features_labeled = features[features[0].isin(labeled_ids)]\n",
    "# class_labeled = classes[classes['class'] != 'unknown']\n",
    "\n",
    "# # Convert to PyG Data format\n",
    "# x = torch.tensor(features_labeled.iloc[:, 1:].values, dtype=torch.float)\n",
    "# y = torch.tensor(class_labeled['class'].map({'1':0, '2':1}).values, dtype=torch.long)\n",
    "\n",
    "# # Create edge indices\n",
    "# edge_index = torch.tensor(edgelist.values.T, dtype=torch.long)\n",
    "\n",
    "# # Build graph data object\n",
    "# data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# # Visualize clusters with t-SNE (lightning fast)\n",
    "# tsne = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
    "# embeddings = tsne.fit_transform(data.x.numpy())\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(\n",
    "#     embeddings[:, 0], embeddings[:, 1],\n",
    "#     c=data.y.numpy(), \n",
    "#     cmap='coolwarm', \n",
    "#     alpha=0.6,\n",
    "#     s=10\n",
    "# )\n",
    "# plt.colorbar(label='Fraud Risk (0=Legit, 1=Fraud)')\n",
    "# plt.title(\"t-SNE of Bitcoin Transaction Features\")\n",
    "# plt.savefig(\"fraud_clusters_tsne.png\", dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc2b2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7716b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch_geometric.utils.to_dense_adj(elliptic.edge_index).squeeze()\n",
    "# A_tilde = A + torch.eye(A.shape())\n",
    "# sqrt_node_degrees = torch.sqrt(torch.sum(A_tilde, dim=1))\n",
    "# D_tilde_inv = torch.diag(1/sqrt_node_degrees)\n",
    "\n",
    "# P = D_tilde_inv @ A_tilde @ D_tilde_inv\n",
    "# print(P)\n",
    "# print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "efde3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 16)\n",
    "        self.conv2 = GCNConv(16, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f13da250",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = data.num_node_features\n",
    "out_channels = int(data.y.max().item()) + 1  # handles if labels are not 0-indexed\n",
    "\n",
    "model = GCN(in_channels, out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "68a7dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap='Set2')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = GCN(in_channels, out_channels)\n",
    "model.eval()\n",
    "out = model(data)\n",
    "# visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b284b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "829ff207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 3.1234, Accuracy: 0.2197\n",
      "Epoch: 002, Loss: 2.5267, Accuracy: 0.3033\n",
      "Epoch: 003, Loss: 1.5595, Accuracy: 0.3834\n",
      "Epoch: 004, Loss: 1.1939, Accuracy: 0.4585\n",
      "Epoch: 005, Loss: 0.7375, Accuracy: 0.5132\n",
      "Epoch: 006, Loss: 0.6352, Accuracy: 0.5674\n",
      "Epoch: 007, Loss: 0.5273, Accuracy: 0.6009\n",
      "Epoch: 008, Loss: 0.4905, Accuracy: 0.6316\n",
      "Epoch: 009, Loss: 0.4660, Accuracy: 0.6542\n",
      "Epoch: 010, Loss: 0.4203, Accuracy: 0.6720\n",
      "Epoch: 011, Loss: 0.4223, Accuracy: 0.6876\n",
      "Epoch: 012, Loss: 0.3898, Accuracy: 0.7008\n",
      "Epoch: 013, Loss: 0.3820, Accuracy: 0.7139\n",
      "Epoch: 014, Loss: 0.3704, Accuracy: 0.7245\n",
      "Epoch: 015, Loss: 0.3586, Accuracy: 0.7338\n",
      "Epoch: 016, Loss: 0.3517, Accuracy: 0.7418\n",
      "Epoch: 017, Loss: 0.3460, Accuracy: 0.7479\n",
      "Epoch: 018, Loss: 0.3407, Accuracy: 0.7533\n",
      "Epoch: 019, Loss: 0.3279, Accuracy: 0.7588\n",
      "Epoch: 020, Loss: 0.3258, Accuracy: 0.7631\n",
      "Epoch: 021, Loss: 0.3210, Accuracy: 0.7673\n",
      "Epoch: 022, Loss: 0.3052, Accuracy: 0.7708\n",
      "Epoch: 023, Loss: 0.3064, Accuracy: 0.7741\n",
      "Epoch: 024, Loss: 0.3005, Accuracy: 0.7782\n",
      "Epoch: 025, Loss: 0.3013, Accuracy: 0.7807\n",
      "Epoch: 026, Loss: 0.2949, Accuracy: 0.7834\n",
      "Epoch: 027, Loss: 0.2859, Accuracy: 0.7870\n",
      "Epoch: 028, Loss: 0.2849, Accuracy: 0.7900\n",
      "Epoch: 029, Loss: 0.2818, Accuracy: 0.7922\n",
      "Epoch: 030, Loss: 0.2804, Accuracy: 0.7942\n",
      "Epoch: 031, Loss: 0.2752, Accuracy: 0.7972\n",
      "Epoch: 032, Loss: 0.2746, Accuracy: 0.8005\n",
      "Epoch: 033, Loss: 0.2668, Accuracy: 0.8026\n",
      "Epoch: 034, Loss: 0.2663, Accuracy: 0.8049\n",
      "Epoch: 035, Loss: 0.2599, Accuracy: 0.8068\n",
      "Epoch: 036, Loss: 0.2594, Accuracy: 0.8084\n",
      "Epoch: 037, Loss: 0.2560, Accuracy: 0.8109\n",
      "Epoch: 038, Loss: 0.2528, Accuracy: 0.8137\n",
      "Epoch: 039, Loss: 0.2524, Accuracy: 0.8167\n",
      "Epoch: 040, Loss: 0.2547, Accuracy: 0.8195\n",
      "Epoch: 041, Loss: 0.2477, Accuracy: 0.8221\n",
      "Epoch: 042, Loss: 0.2499, Accuracy: 0.8247\n",
      "Epoch: 043, Loss: 0.2444, Accuracy: 0.8279\n",
      "Epoch: 044, Loss: 0.2448, Accuracy: 0.8314\n",
      "Epoch: 045, Loss: 0.2403, Accuracy: 0.8351\n",
      "Epoch: 046, Loss: 0.2386, Accuracy: 0.8377\n",
      "Epoch: 047, Loss: 0.2390, Accuracy: 0.8409\n",
      "Epoch: 048, Loss: 0.2374, Accuracy: 0.8445\n",
      "Epoch: 049, Loss: 0.2384, Accuracy: 0.8493\n",
      "Epoch: 050, Loss: 0.2357, Accuracy: 0.8537\n",
      "Epoch: 051, Loss: 0.2359, Accuracy: 0.8567\n",
      "Epoch: 052, Loss: 0.2346, Accuracy: 0.8597\n",
      "Epoch: 053, Loss: 0.2321, Accuracy: 0.8623\n",
      "Epoch: 054, Loss: 0.2317, Accuracy: 0.8638\n",
      "Epoch: 055, Loss: 0.2322, Accuracy: 0.8659\n",
      "Epoch: 056, Loss: 0.2325, Accuracy: 0.8676\n",
      "Epoch: 057, Loss: 0.2306, Accuracy: 0.8689\n",
      "Epoch: 058, Loss: 0.2294, Accuracy: 0.8702\n",
      "Epoch: 059, Loss: 0.2290, Accuracy: 0.8712\n",
      "Epoch: 060, Loss: 0.2252, Accuracy: 0.8717\n",
      "Epoch: 061, Loss: 0.2251, Accuracy: 0.8725\n",
      "Epoch: 062, Loss: 0.2262, Accuracy: 0.8741\n",
      "Epoch: 063, Loss: 0.2260, Accuracy: 0.8756\n",
      "Epoch: 064, Loss: 0.2248, Accuracy: 0.8786\n",
      "Epoch: 065, Loss: 0.2227, Accuracy: 0.8806\n",
      "Epoch: 066, Loss: 0.2207, Accuracy: 0.8824\n",
      "Epoch: 067, Loss: 0.2249, Accuracy: 0.8849\n",
      "Epoch: 068, Loss: 0.2221, Accuracy: 0.8863\n",
      "Epoch: 069, Loss: 0.2221, Accuracy: 0.8881\n",
      "Epoch: 070, Loss: 0.2246, Accuracy: 0.8896\n",
      "Epoch: 071, Loss: 0.2198, Accuracy: 0.8905\n",
      "Epoch: 072, Loss: 0.2206, Accuracy: 0.8920\n",
      "Epoch: 073, Loss: 0.2175, Accuracy: 0.8938\n",
      "Epoch: 074, Loss: 0.2198, Accuracy: 0.8951\n",
      "Epoch: 075, Loss: 0.2189, Accuracy: 0.8969\n",
      "Epoch: 076, Loss: 0.2205, Accuracy: 0.8987\n",
      "Epoch: 077, Loss: 0.2164, Accuracy: 0.8998\n",
      "Epoch: 078, Loss: 0.2156, Accuracy: 0.9010\n",
      "Epoch: 079, Loss: 0.2180, Accuracy: 0.9015\n",
      "Epoch: 080, Loss: 0.2177, Accuracy: 0.9019\n",
      "Epoch: 081, Loss: 0.2150, Accuracy: 0.9025\n",
      "Epoch: 082, Loss: 0.2170, Accuracy: 0.9028\n",
      "Epoch: 083, Loss: 0.2149, Accuracy: 0.9032\n",
      "Epoch: 084, Loss: 0.2160, Accuracy: 0.9040\n",
      "Epoch: 085, Loss: 0.2138, Accuracy: 0.9044\n",
      "Epoch: 086, Loss: 0.2169, Accuracy: 0.9050\n",
      "Epoch: 087, Loss: 0.2165, Accuracy: 0.9060\n",
      "Epoch: 088, Loss: 0.2131, Accuracy: 0.9064\n",
      "Epoch: 089, Loss: 0.2135, Accuracy: 0.9069\n",
      "Epoch: 090, Loss: 0.2104, Accuracy: 0.9082\n",
      "Epoch: 091, Loss: 0.2162, Accuracy: 0.9088\n",
      "Epoch: 092, Loss: 0.2109, Accuracy: 0.9094\n",
      "Epoch: 093, Loss: 0.2130, Accuracy: 0.9098\n",
      "Epoch: 094, Loss: 0.2136, Accuracy: 0.9104\n",
      "Epoch: 095, Loss: 0.2127, Accuracy: 0.9111\n",
      "Epoch: 096, Loss: 0.2097, Accuracy: 0.9117\n",
      "Epoch: 097, Loss: 0.2086, Accuracy: 0.9122\n",
      "Epoch: 098, Loss: 0.2087, Accuracy: 0.9125\n",
      "Epoch: 099, Loss: 0.2117, Accuracy: 0.9130\n",
      "Epoch: 100, Loss: 0.2107, Accuracy: 0.9132\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript\n",
    "\n",
    "model = GCN(in_channels, out_channels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
    "    return test_acc\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(data)\n",
    "    test_acc = test(data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a304429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9132\n"
     ]
    }
   ],
   "source": [
    "test_acc = test(data)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebafcd90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      3\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# visualize(out, color=data.y)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "out = model(data)\n",
    "# visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea277d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(dataset[:400], batch_size=203769, shuffle=True)\n",
    "# test_loader = DataLoader(dataset[400:], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn.pool import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PoolingGCN(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = GCNConv(165, 512, catched=False)\n",
    "#         self.conv2 = GCNConv(512, 2, catched=False)\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x =  global_mean_pool(x, data.batch)\n",
    "\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d272c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (203769).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_acc\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[1;32m---> 26\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[163], line 10\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m out \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (203769)."
     ]
    }
   ],
   "source": [
    "# model = PoolingGCN()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# def train_step(train_loader):\n",
    "#     model.train()\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(batch)\n",
    "#         loss = criterion(out, batch.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     return loss\n",
    "\n",
    "# def test_step(test_loader):\n",
    "#     model.eval()\n",
    "#     for batch in test_loader:\n",
    "#         out = model(batch)\n",
    "#         pred = out.argmax(dim=1)\n",
    "#         test_correct = pred[batch.test_mask] == batch.y[batch.test_mask]\n",
    "#         test_acc = int(test_correct.sum()) / int(batch.test_mask.sum())\n",
    "#     return test_acc\n",
    "\n",
    "\n",
    "# for epoch in range(1, 101):\n",
    "#     train_loss = train_step(train_loader)\n",
    "#     if not epoch%10:\n",
    "#         print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c225f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
